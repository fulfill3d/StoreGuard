<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Frame Streaming</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/microsoft-signalr/7.0.0/signalr.min.js"></script>
</head>
<body>
<h2>WebRTC Frame Streaming</h2>
<video id="localVideo" autoplay playsinline></video>
<script>
    const videoElement = document.getElementById("localVideo");
    const hubConnection = new signalR.HubConnectionBuilder()
        .withUrl("http://localhost:5026/videoHub", { withCredentials: true })
        .configureLogging(signalR.LogLevel.Information)
        .build();

    // Define source and camera identifiers
    const sourceId = "source-123"; // Replace with dynamic source ID if needed
    const cameraId = "camera-001"; // Replace with dynamic camera ID if needed
    const timestamp = new Date().toISOString();

    // Function to capture and send frames at a low rate
    async function captureAndSendFrames(stream, frameRate = 1) {
        // Create a canvas to extract frames from the video
        const canvas = document.createElement('canvas');
        const context = canvas.getContext('2d');
        canvas.width = videoElement.videoWidth || 640; // Default width
        canvas.height = videoElement.videoHeight || 480; // Default height

        // Adjust the frame interval based on the desired frame rate
        const frameInterval = 1000 / frameRate;

        // Capture frames at the specified rate
        setInterval(() => {
            try {
                // Ensure the canvas dimensions match the video dimensions dynamically
                canvas.width = videoElement.videoWidth;
                canvas.height = videoElement.videoHeight;
                
                // Draw the current frame from the video onto the canvas
                context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

                // Convert the canvas content to a Base64-encoded JPEG image
                const fullBase64 = canvas.toDataURL('image/jpeg');
                const frameData = fullBase64.split(',')[1]; // Extract Base64 data

                // Send the frame data to the backend using SignalR
                hubConnection.invoke("SendVideoData", frameData, sourceId, cameraId, timestamp)
                    .then(() => console.log("Frame sent successfully"))
                    .catch(err => console.error("Error sending frame:", err));
            } catch (error) {
                console.error("Error capturing and sending frame:", error);
            }
        }, frameInterval);
    }

    async function startVideo() {
        try {
            // Get the video stream from the user's camera
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            videoElement.srcObject = stream;

            // Ensure the video starts playing
            await videoElement.play();

            // Start capturing and sending frames
            await captureAndSendFrames(stream);
        } catch (error) {
            console.error("Error accessing camera:", error);
        }
    }


    async function connectSignalR() {
        try {
            await hubConnection.start();
            console.log("SignalR connected");
        } catch (err) {
            console.error("Error connecting to SignalR:", err);
            setTimeout(connectSignalR, 3000); // Retry connection after 3 seconds
        }
    }

    // Initialize SignalR connection and start the video stream
    connectSignalR();
    startVideo();
</script>
</body>
</html>
